{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9\n",
    "\n",
    "## Mashable news stories analysis\n",
    "\n",
    "Predicting if a news story is going to be popular\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>Popular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://mashable.com/2014/12/10/cia-torture-rep...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0.732620</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.844262</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.487500</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://mashable.com/2013/10/18/bitlock-kicksta...</td>\n",
       "      <td>447.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0.653199</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.135340</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://mashable.com/2013/07/24/google-glass-po...</td>\n",
       "      <td>533.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.660377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://mashable.com/2013/11/21/these-are-the-m...</td>\n",
       "      <td>413.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.497409</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.677350</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.195701</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://mashable.com/2014/02/11/parking-ticket-...</td>\n",
       "      <td>331.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.830357</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.55</td>\n",
       "      <td>-0.175000</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  timedelta  \\\n",
       "0  http://mashable.com/2014/12/10/cia-torture-rep...       28.0   \n",
       "1  http://mashable.com/2013/10/18/bitlock-kicksta...      447.0   \n",
       "2  http://mashable.com/2013/07/24/google-glass-po...      533.0   \n",
       "3  http://mashable.com/2013/11/21/these-are-the-m...      413.0   \n",
       "4  http://mashable.com/2014/02/11/parking-ticket-...      331.0   \n",
       "\n",
       "   n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
       "0             9.0             188.0         0.732620               1.0   \n",
       "1             7.0             297.0         0.653199               1.0   \n",
       "2            11.0             181.0         0.660377               1.0   \n",
       "3            12.0             781.0         0.497409               1.0   \n",
       "4             8.0             177.0         0.685714               1.0   \n",
       "\n",
       "   n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs   ...     \\\n",
       "0                  0.844262        5.0             1.0       1.0   ...      \n",
       "1                  0.815789        9.0             4.0       1.0   ...      \n",
       "2                  0.775701        4.0             3.0       1.0   ...      \n",
       "3                  0.677350       10.0             3.0       1.0   ...      \n",
       "4                  0.830357        3.0             2.0       1.0   ...      \n",
       "\n",
       "   min_positive_polarity  max_positive_polarity  avg_negative_polarity  \\\n",
       "0               0.200000                   0.80              -0.487500   \n",
       "1               0.160000                   0.50              -0.135340   \n",
       "2               0.136364                   1.00               0.000000   \n",
       "3               0.100000                   1.00              -0.195701   \n",
       "4               0.100000                   0.55              -0.175000   \n",
       "\n",
       "   min_negative_polarity  max_negative_polarity  title_subjectivity  \\\n",
       "0                  -0.60              -0.250000                 0.9   \n",
       "1                  -0.40              -0.050000                 0.1   \n",
       "2                   0.00               0.000000                 0.3   \n",
       "3                  -0.40              -0.071429                 0.0   \n",
       "4                  -0.25              -0.100000                 0.0   \n",
       "\n",
       "   title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "0                       0.8                     0.4   \n",
       "1                      -0.1                     0.4   \n",
       "2                       1.0                     0.2   \n",
       "3                       0.0                     0.5   \n",
       "4                       0.0                     0.5   \n",
       "\n",
       "   abs_title_sentiment_polarity  Popular  \n",
       "0                           0.8        1  \n",
       "1                           0.1        0  \n",
       "2                           1.0        0  \n",
       "3                           0.0        0  \n",
       "4                           0.0        0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/albahnsen/PracticalMachineLearningClass/master/datasets/mashable.csv'\n",
    "train_df = pd.read_csv(url, index_col=0)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 61)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(['url', 'Popular'], axis=1)\n",
    "y = train_df['Popular']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.1\n",
    "\n",
    "Estimate a Decision Tree Classifier and a Logistic Regresion\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score\n",
      "lr 0.7784448422854952\n",
      "dt 0.7268784181850604\n",
      "Accuracy\n",
      "lr 0.7886697661252141\n",
      "dt 0.7270946751741939\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "models = {'lr': LogisticRegression(),\n",
    "          'dt': DecisionTreeClassifier()}\n",
    "\n",
    "for model in models.keys():\n",
    "    models[model].fit(X_train, y_train)\n",
    "\n",
    "y_pred = pd.DataFrame(columns=models.keys())\n",
    "for model in models.keys():\n",
    "    y_pred[model] = models[model].predict(X_test)\n",
    "   \n",
    "    \n",
    "from sklearn import metrics\n",
    "print('f1_score')\n",
    "for model in models.keys():\n",
    "    print(model,np.sqrt(metrics.f1_score(y_pred[model], y_test)))   \n",
    "print('Accuracy')\n",
    "\n",
    "for model in models.keys():\n",
    "    print(model,np.sqrt(metrics.accuracy_score(y_pred[model], y_test)))   \n",
    "#dfgdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.2\n",
    "\n",
    "Estimate 300 bagged samples\n",
    "\n",
    "Estimate the following set of classifiers:\n",
    "\n",
    "* 100 Decision Trees where max_depth=None\n",
    "* 100 Decision Trees where max_depth=2\n",
    "* 100 Logistic Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "models2 = {'dt': DecisionTreeClassifier(max_depth=None),\n",
    "          'dtdep2': DecisionTreeClassifier(max_depth=2),\n",
    "          'lr': LogisticRegression()}\n",
    "\n",
    "y_pred2 = pd.DataFrame(columns=models2.keys())\n",
    "for model2 in models2.keys():\n",
    "    models2[model2] = BaggingClassifier(base_estimator=models2[model2], n_estimators=100, bootstrap=True,\n",
    "                        random_state=1, n_jobs=-1, oob_score=True).fit(X_train, y_train)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.3\n",
    "\n",
    "Ensemble using majority voting\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 100\n",
    "# set a seed for reproducibility\n",
    "np.random.seed(123)\n",
    "\n",
    "n_samples = X_train.shape[0]\n",
    "\n",
    "# create bootstrap samples (will be used to select rows from the DataFrame)\n",
    "samples = [np.random.choice(a=n_samples, size=n_samples, replace=True) for _ in range(n_estimators)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "np.random.seed(123) \n",
    "seeds = np.random.randint(1, 10000, size=n_estimators)\n",
    "\n",
    "trees = {}\n",
    "for i in range(n_estimators):\n",
    "    trees[i] = DecisionTreeClassifier(max_features=\"sqrt\", max_depth=None, random_state=seeds[i])\n",
    "    trees[i].fit(X_train.iloc[samples[i]], y_train.iloc[samples[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       0   1   2   3   4   5   6   7   8   9  ...  90  91  92  93  94  95  96  \\\n",
       "1782   1   1   1   1   0   1   1   1   1   1 ...   1   1   0   1   0   0   0   \n",
       "3917   0   1   0   0   0   1   1   0   0   1 ...   1   0   1   0   0   1   0   \n",
       "221    1   1   0   0   1   0   0   1   0   0 ...   0   1   0   0   0   0   1   \n",
       "2135   0   0   0   0   0   0   1   0   0   1 ...   0   0   1   0   0   1   0   \n",
       "5224   1   0   1   1   0   0   1   0   1   0 ...   1   0   0   0   1   0   0   \n",
       "1168   0   0   0   0   1   0   1   0   1   1 ...   1   0   1   0   0   1   0   \n",
       "879    0   0   1   0   0   0   0   0   0   0 ...   0   0   1   0   0   0   0   \n",
       "156    0   0   1   0   0   0   0   1   1   1 ...   0   0   0   0   0   1   0   \n",
       "1657   1   1   0   1   1   1   1   1   1   1 ...   0   0   0   1   1   1   1   \n",
       "323    0   1   0   1   0   0   0   0   0   0 ...   0   0   0   0   0   0   0   \n",
       "5302   1   0   1   0   0   0   1   0   1   1 ...   0   0   0   1   0   1   0   \n",
       "2611   0   1   1   1   0   0   1   0   1   1 ...   0   0   0   1   0   0   0   \n",
       "811    0   0   0   0   1   1   0   1   0   0 ...   0   1   1   0   0   0   1   \n",
       "393    0   1   1   1   0   1   1   1   0   1 ...   1   0   1   0   1   1   0   \n",
       "3593   0   1   1   1   0   0   0   0   0   0 ...   0   1   0   0   0   0   1   \n",
       "2638   0   0   1   1   1   0   1   1   1   1 ...   0   0   0   1   0   1   1   \n",
       "2187   1   1   0   0   1   0   1   1   1   0 ...   1   0   1   0   1   0   0   \n",
       "5351   0   0   0   0   0   1   1   0   0   0 ...   0   0   1   0   0   0   0   \n",
       "319    0   0   0   0   1   0   0   0   0   0 ...   0   0   1   0   0   0   0   \n",
       "167    0   1   1   1   1   1   1   1   1   1 ...   1   0   1   1   1   1   1   \n",
       "746    1   1   1   1   0   0   1   1   1   1 ...   1   1   1   1   1   1   1   \n",
       "5470   0   0   1   1   1   1   1   1   0   1 ...   1   0   0   1   1   1   1   \n",
       "3707   1   1   1   1   0   1   0   1   0   0 ...   0   1   0   1   0   1   0   \n",
       "2764   1   1   0   1   0   1   0   1   0   1 ...   0   0   1   1   1   0   1   \n",
       "5112   1   1   0   0   0   0   0   1   1   1 ...   1   1   0   1   0   0   0   \n",
       "4006   0   0   0   1   1   0   1   1   1   1 ...   1   1   0   1   0   0   0   \n",
       "1871   1   0   0   1   0   0   0   1   0   1 ...   1   0   1   1   1   0   1   \n",
       "5756   1   1   1   0   0   1   1   1   1   1 ...   1   1   1   1   0   1   1   \n",
       "3193   0   1   1   1   1   1   1   1   1   1 ...   1   0   0   1   0   0   1   \n",
       "3754   1   1   0   1   1   1   1   1   1   1 ...   1   1   0   1   0   0   0   \n",
       "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  .. ...  ..  ..  ..  ..  ..  ..  ..   \n",
       "3628   0   0   1   1   1   1   0   1   1   0 ...   0   0   0   1   0   1   1   \n",
       "4829   0   0   0   0   1   0   0   0   1   1 ...   0   0   0   0   0   0   0   \n",
       "2149   1   1   0   0   0   0   1   0   1   0 ...   1   0   0   0   0   0   1   \n",
       "139    1   0   1   0   0   1   0   1   1   1 ...   1   0   0   0   1   0   0   \n",
       "5829   1   0   1   1   1   1   1   0   1   1 ...   0   1   1   1   0   1   1   \n",
       "5274   1   0   0   1   1   1   1   0   1   0 ...   1   1   1   1   1   1   1   \n",
       "2284   0   0   1   0   0   1   1   1   1   0 ...   1   0   0   0   0   0   1   \n",
       "5010   0   1   1   1   1   1   1   1   1   1 ...   1   0   0   1   1   1   1   \n",
       "1149   1   1   1   1   1   1   1   1   1   1 ...   0   1   1   1   1   1   1   \n",
       "4048   1   0   0   0   1   1   1   0   0   0 ...   1   0   1   1   1   0   1   \n",
       "2498   1   0   0   0   0   1   1   1   1   0 ...   0   1   0   0   0   0   0   \n",
       "2273   1   0   1   0   0   0   1   1   0   0 ...   1   0   0   1   1   0   1   \n",
       "2526   0   1   1   1   1   1   1   1   1   1 ...   1   1   1   1   1   1   0   \n",
       "463    0   0   1   0   1   0   0   0   0   0 ...   0   0   0   0   0   0   0   \n",
       "3307   1   0   0   1   1   0   1   1   1   0 ...   0   1   1   1   1   1   0   \n",
       "3132   1   0   0   1   0   1   0   1   0   0 ...   1   0   1   1   1   1   0   \n",
       "4985   1   1   1   0   1   0   0   1   0   1 ...   0   1   1   1   0   0   0   \n",
       "594    1   0   1   1   1   0   1   0   0   1 ...   1   1   1   1   1   1   1   \n",
       "3080   1   0   1   0   0   0   1   0   0   0 ...   0   0   0   0   0   1   0   \n",
       "1807   1   0   0   1   1   1   1   1   1   1 ...   1   0   1   1   1   0   1   \n",
       "5136   0   0   1   0   0   1   0   1   0   0 ...   0   0   1   0   0   0   0   \n",
       "450    1   1   1   1   1   1   1   1   1   1 ...   1   1   1   1   0   1   1   \n",
       "3043   0   0   0   1   0   0   1   0   0   0 ...   0   0   0   1   0   1   0   \n",
       "5826   0   0   0   0   1   0   0   0   0   1 ...   0   1   1   0   0   0   0   \n",
       "518    0   0   0   1   0   0   0   0   1   0 ...   0   0   0   1   0   0   1   \n",
       "2522   0   0   1   1   0   1   1   0   1   0 ...   0   0   1   0   0   0   0   \n",
       "312    1   1   1   1   1   1   1   0   0   0 ...   1   1   1   1   1   0   1   \n",
       "5887   1   0   0   1   0   0   1   0   1   1 ...   0   1   0   0   0   1   0   \n",
       "4483   0   0   0   1   1   1   1   1   1   0 ...   1   0   0   1   1   0   1   \n",
       "2647   1   0   1   0   0   1   0   0   0   1 ...   0   0   1   0   1   0   1   \n",
       "\n",
       "      97  98  99  \n",
       "1782   1   1   0  \n",
       "3917   0   0   1  \n",
       "221    0   1   1  \n",
       "2135   0   0   0  \n",
       "5224   0   0   1  \n",
       "1168   1   1   1  \n",
       "879    0   0   1  \n",
       "156    0   0   0  \n",
       "1657   0   1   0  \n",
       "323    1   0   0  \n",
       "5302   1   1   1  \n",
       "2611   0   0   0  \n",
       "811    1   0   0  \n",
       "393    1   1   1  \n",
       "3593   0   1   1  \n",
       "2638   0   0   1  \n",
       "2187   1   1   0  \n",
       "5351   1   1   1  \n",
       "319    1   0   1  \n",
       "167    1   1   1  \n",
       "746    1   1   1  \n",
       "5470   1   1   0  \n",
       "3707   0   1   0  \n",
       "2764   1   1   0  \n",
       "5112   0   1   0  \n",
       "4006   0   1   0  \n",
       "1871   1   0   1  \n",
       "5756   1   1   0  \n",
       "3193   0   1   1  \n",
       "3754   0   1   0  \n",
       "...   ..  ..  ..  \n",
       "3628   0   0   0  \n",
       "4829   0   1   0  \n",
       "2149   0   0   0  \n",
       "139    0   0   1  \n",
       "5829   1   1   1  \n",
       "5274   1   1   0  \n",
       "2284   0   1   0  \n",
       "5010   0   1   1  \n",
       "1149   1   1   0  \n",
       "4048   1   0   1  \n",
       "2498   0   1   1  \n",
       "2273   0   1   1  \n",
       "2526   1   1   1  \n",
       "463    0   0   0  \n",
       "3307   0   1   1  \n",
       "3132   0   0   1  \n",
       "4985   1   0   0  \n",
       "594    0   1   1  \n",
       "3080   1   0   0  \n",
       "1807   0   1   1  \n",
       "5136   0   0   1  \n",
       "450    1   1   1  \n",
       "3043   0   0   0  \n",
       "5826   0   0   0  \n",
       "518    0   0   0  \n",
       "2522   0   1   1  \n",
       "312    0   0   0  \n",
       "5887   0   0   1  \n",
       "4483   1   0   1  \n",
       "2647   0   1   0  \n",
       "\n",
       "[1980 rows x 100 columns]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_df = pd.DataFrame(index=X_test.index, columns=list(range(n_estimators)))\n",
    "for i in range(n_estimators):\n",
    "    y_pred_df.iloc[:, i] = trees[i].predict(X_test)\n",
    "\n",
    "y_pred_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6459689534301452"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = (y_pred_df.sum(axis=1) >= (n_estimators / 2)).astype(np.int)\n",
    "\n",
    "from sklearn import metrics\n",
    "metrics.f1_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6429292929292929"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100, bootstrap=True,\n",
    "                        random_state=42, n_jobs=-1, oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6318484383000512, 0.6368686868686869)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "metrics.f1_score(y_pred, y_test), metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.4\n",
    "\n",
    "Estimate te probability as %models that predict positive\n",
    "\n",
    "Modify the probability threshold and select the one that maximizes the F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1782    62\n",
       "3917    45\n",
       "221     44\n",
       "2135    22\n",
       "5224    27\n",
       "1168    40\n",
       "879     18\n",
       "156     25\n",
       "1657    62\n",
       "323     23\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts().to_frame('count').assign(percentage = lambda x: x/x.sum())\n",
    "y_pred_df.sum(axis=1)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.545959595959596\n",
      "0.5515151515151515\n",
      "0.5686868686868687\n",
      "0.5363636363636364\n",
      "0.5772727272727273\n",
      "0.5646464646464646\n",
      "0.5494949494949495\n",
      "0.5651515151515152\n",
      "0.5535353535353535\n",
      "0.555050505050505\n",
      "0.548989898989899\n",
      "0.5631313131313131\n",
      "0.5247474747474747\n",
      "0.5747474747474748\n",
      "0.5595959595959596\n",
      "0.5373737373737374\n",
      "0.5545454545454546\n",
      "0.555050505050505\n",
      "0.5772727272727273\n",
      "0.5601010101010101\n",
      "0.5565656565656566\n",
      "0.5717171717171717\n",
      "0.5494949494949495\n",
      "0.543939393939394\n",
      "0.5737373737373738\n",
      "0.5606060606060606\n",
      "0.5636363636363636\n",
      "0.55\n",
      "0.5585858585858586\n",
      "0.5646464646464646\n",
      "0.5641414141414142\n",
      "0.556060606060606\n",
      "0.5590909090909091\n",
      "0.5580808080808081\n",
      "0.5555555555555556\n",
      "0.5782828282828283\n",
      "0.5858585858585859\n",
      "0.5404040404040404\n",
      "0.5585858585858586\n",
      "0.557070707070707\n",
      "0.5555555555555556\n",
      "0.555050505050505\n",
      "0.5535353535353535\n",
      "0.5444444444444444\n",
      "0.557070707070707\n",
      "0.5656565656565656\n",
      "0.5434343434343434\n",
      "0.554040404040404\n",
      "0.5368686868686868\n",
      "0.5702020202020202\n",
      "0.5409090909090909\n",
      "0.5434343434343434\n",
      "0.5707070707070707\n",
      "0.5621212121212121\n",
      "0.5565656565656566\n",
      "0.5696969696969697\n",
      "0.5661616161616162\n",
      "0.5661616161616162\n",
      "0.5398989898989899\n",
      "0.5575757575757576\n",
      "0.547979797979798\n",
      "0.5565656565656566\n",
      "0.547979797979798\n",
      "0.5484848484848485\n",
      "0.55\n",
      "0.5666666666666667\n",
      "0.5621212121212121\n",
      "0.5722222222222222\n",
      "0.5681818181818182\n",
      "0.553030303030303\n",
      "0.5616161616161616\n",
      "0.5580808080808081\n",
      "0.5666666666666667\n",
      "0.5515151515151515\n",
      "0.5429292929292929\n",
      "0.5535353535353535\n",
      "0.5868686868686869\n",
      "0.5893939393939394\n",
      "0.5747474747474748\n",
      "0.5535353535353535\n",
      "0.5515151515151515\n",
      "0.5545454545454546\n",
      "0.5616161616161616\n",
      "0.5616161616161616\n",
      "0.543939393939394\n",
      "0.5702020202020202\n",
      "0.5606060606060606\n",
      "0.554040404040404\n",
      "0.5373737373737374\n",
      "0.5535353535353535\n",
      "0.546969696969697\n",
      "0.5732323232323232\n",
      "0.5616161616161616\n",
      "0.5419191919191919\n",
      "0.5601010101010101\n",
      "0.5651515151515152\n",
      "0.5626262626262626\n",
      "0.5535353535353535\n",
      "0.5631313131313131\n",
      "0.5722222222222222\n"
     ]
    }
   ],
   "source": [
    "res=[]\n",
    "for i in range(y_pred_df.shape[1]):\n",
    "    print(metrics.accuracy_score(y_pred_df.iloc[:,i], y_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5424936386768447\n",
      "0.5455475946775844\n",
      "0.5647298674821611\n",
      "0.5344827586206897\n",
      "0.5821268097853219\n",
      "0.563323201621074\n",
      "0.5508559919436052\n",
      "0.5649317837291561\n",
      "0.5508130081300813\n",
      "0.5479733196511031\n",
      "0.5413456599897277\n",
      "0.5566376217324449\n",
      "0.5292646323161581\n",
      "0.5734549138804458\n",
      "0.5683168316831684\n",
      "0.5429141716566865\n",
      "0.5545454545454545\n",
      "0.5451729478575117\n",
      "0.5804511278195489\n",
      "0.5620915032679739\n",
      "0.557013118062563\n",
      "0.5751503006012024\n",
      "0.5444330949948928\n",
      "0.5399898115129904\n",
      "0.5800995024875623\n",
      "0.5561224489795918\n",
      "0.5541795665634676\n",
      "0.545176110260337\n",
      "0.5599194360523666\n",
      "0.5597548518896833\n",
      "0.5621511922881787\n",
      "0.5646359583952452\n",
      "0.5575266092245312\n",
      "0.5614035087719297\n",
      "0.5652173913043478\n",
      "0.5689210118740321\n",
      "0.5799180327868853\n",
      "0.5404040404040404\n",
      "0.5643070787637089\n",
      "0.5523226135783563\n",
      "0.5542046605876393\n",
      "0.5561712846347607\n",
      "0.5512690355329949\n",
      "0.5407331975560081\n",
      "0.5617191404297851\n",
      "0.553478712357217\n",
      "0.5354573484069887\n",
      "0.5460154241645244\n",
      "0.5356962025316456\n",
      "0.5712846347607052\n",
      "0.5326478149100257\n",
      "0.55203171456888\n",
      "0.5645491803278689\n",
      "0.5662831415707854\n",
      "0.5524974515800204\n",
      "0.572289156626506\n",
      "0.5556130367304708\n",
      "0.5749628896585849\n",
      "0.5296850800206505\n",
      "0.5507692307692308\n",
      "0.5412608918503332\n",
      "0.5506653019447287\n",
      "0.5513784461152883\n",
      "0.5343749999999999\n",
      "0.5470259278088461\n",
      "0.5666666666666667\n",
      "0.5645404319437469\n",
      "0.5750125439036627\n",
      "0.5626598465473146\n",
      "0.5477772100153296\n",
      "0.5580448065173116\n",
      "0.5600804424333836\n",
      "0.5684104627766601\n",
      "0.5432098765432098\n",
      "0.5399084900864259\n",
      "0.5562248995983936\n",
      "0.5787847579814624\n",
      "0.5896012115093386\n",
      "0.5773092369477912\n",
      "0.5553319919517102\n",
      "0.5436793422404933\n",
      "0.5504587155963302\n",
      "0.5593908629441625\n",
      "0.562058526740666\n",
      "0.5460030165912518\n",
      "0.5678009141696293\n",
      "0.5406546990496304\n",
      "0.560039860488291\n",
      "0.5345528455284553\n",
      "0.5610724925521351\n",
      "0.5378670788253477\n",
      "0.5651055069480185\n",
      "0.5497925311203319\n",
      "0.5480817140009965\n",
      "0.5620915032679739\n",
      "0.5658093797276853\n",
      "0.5635080645161289\n",
      "0.5521783181357649\n",
      "0.5668502754131197\n",
      "0.5707045108971109\n"
     ]
    }
   ],
   "source": [
    "res1=[]\n",
    "for i in range(y_pred_df.shape[1]):\n",
    "    print(metrics.f1_score(y_pred_df.iloc[:,i], y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.5\n",
    "\n",
    "Ensemble using weighted voting using the oob_error\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6318484383000512, 0.6368686868686869)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100, bootstrap=True,\n",
    "                        random_state=42, n_jobs=-1, oob_score=True)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "metrics.f1_score(y_pred, y_test), metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = np.zeros(clf.n_estimators)\n",
    "y_pred_all_ = np.zeros((X_test.shape[0], clf.n_estimators))\n",
    "\n",
    "for i in range(clf.n_estimators):\n",
    "    oob_sample = ~clf.estimators_samples_[i]\n",
    "    y_pred_ = clf.estimators_[i].predict(X_train.values[oob_sample])\n",
    "    errors[i] = metrics.accuracy_score(y_pred_, y_train.values[oob_sample])\n",
    "    y_pred_all_[:, i] = clf.estimators_[i].predict(X_test)\n",
    "    \n",
    "alpha = (1 - errors) / (1 - errors).sum()\n",
    "y_pred = (np.sum(y_pred_all_ * alpha, axis=1) >= 0.5).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6345666497719209, 0.6358585858585859)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(y_pred, y_test), metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.6\n",
    "\n",
    "Estimate te probability of the weighted voting\n",
    "\n",
    "Modify the probability threshold and select the one that maximizes the F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_oob = []\n",
    "for sample in samples:\n",
    "    samples_oob.append(sorted(set(range(n_samples)) - set(sample)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = np.zeros(n_estimators)\n",
    "\n",
    "for i in range(n_estimators):\n",
    "    y_pred_ = trees[i].predict(X_train.iloc[samples_oob[i]])\n",
    "    errors[i] = 1 - metrics.accuracy_score(y_train.iloc[samples_oob[i]], y_pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'OOB error of each tree')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "plt.scatter(range(n_estimators), errors)\n",
    "plt.xlim([0, n_estimators])\n",
    "plt.title('OOB error of each tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = (1 - errors) / (1 - errors).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_sum_1 = ((y_pred_df) * alpha).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1782    0.619934\n",
       "3917    0.451088\n",
       "221     0.440955\n",
       "2135    0.218923\n",
       "5224    0.269455\n",
       "1168    0.399922\n",
       "879     0.180798\n",
       "156     0.249498\n",
       "1657    0.618445\n",
       "323     0.230200\n",
       "5302    0.549160\n",
       "2611    0.257783\n",
       "811     0.391105\n",
       "393     0.661003\n",
       "3593    0.440661\n",
       "2638    0.529319\n",
       "2187    0.610617\n",
       "5351    0.451057\n",
       "319     0.110776\n",
       "167     0.769944\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_sum_1.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6378872524123921, 0.6398989898989899)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = (weighted_sum_1 >= 0.5).astype(np.int)\n",
    "\n",
    "metrics.f1_score(y_pred, y_test), metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.7\n",
    "\n",
    "Estimate a logistic regression using as input the estimated classifiers\n",
    "\n",
    "Modify the probability threshold such that maximizes the F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2 = pd.DataFrame(index=X_train.index, columns=list(range(n_estimators))) #cada modelo hace overfitin\n",
    "\n",
    "for i in range(n_estimators):\n",
    "    X_train_2[i] = trees[i].predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv=5, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='warn', n_jobs=None, penalty='l2',\n",
       "           random_state=None, refit=True, scoring=None, solver='lbfgs',\n",
       "           tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "lr = LogisticRegressionCV(cv = 5 )\n",
    "lr.fit(X_train_2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(y_pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6372498717290918, 0.6429292929292929)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(y_pred, y_test), metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6325486182190379, 0.6373737373737374)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_all_ = np.zeros((X_test.shape[0], clf.n_estimators))\n",
    "X_train_3 = np.zeros((X_train.shape[0], clf.n_estimators))\n",
    "\n",
    "for i in range(clf.n_estimators):\n",
    "\n",
    "    X_train_3[:, i] = clf.estimators_[i].predict(X_train)\n",
    "    y_pred_all_[:, i] = clf.estimators_[i].predict(X_test)\n",
    "    \n",
    "lr = LogisticRegressionCV(cv=5)\n",
    "lr.fit(X_train_3, y_train)\n",
    "\n",
    "y_pred = lr.predict(y_pred_all_)\n",
    "metrics.f1_score(y_pred, y_test), metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5777554101660795, 0.5762626262626263)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "metrics.f1_score(y_pred, y_test), metrics.accuracy_score(y_pred, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
