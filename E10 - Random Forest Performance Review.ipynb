{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Necesitamos cientos de clasificadores para resolver problemas de clasificación del mundo real?\n",
    "\n",
    "\n",
    "Este trabajos experimental, evaluo a 179 clasificadores en más de 121 conjuntos de datos donde  parallel random forest alcanza el 94.1% de la precisión máxima, superando el 90% en el 84.3% de los conjuntos de datos, muy de seguido de SVM con kernel gaussiano implementado en C utilizando LibSVM, que alcanza el 92.3% de la precisión máxima demostrando que la familia de clasificadores mas robusta es la de random forest.\n",
    "\n",
    "A pesar de que random forest es un método antiguo podemos ver como tiene un mejor desempeño en diferentes conjuntos de datos y también demostró ser el mejor cuando aumenta la complejidad #patterns y #inputs del conjunto de datos, y también es bueno cuando disminuyen #patterns (rf t es el mejor) y #classes aumentan (svm C es el mejor).\n",
    "\n",
    "También están muy cerca del top las familias declasificadores, incluidas otras redes neuronales (funciones de base radial, cuantificación de vectores de aprendizaje y correlación en cascada), análisis discriminantes, árboles de decisión distintos de C5.0, clasificadores basados en reglas, otros conjuntos de bagging y refuerzo, vecinos más cercanos, Bayesiano, GLM, PLSR, MARS, etc., no son competitivos en absoluto.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
